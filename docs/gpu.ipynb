{
   "cells": [
      {
         "attachments": {},
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# Compiling to GPU w/ xDSL through MLIR\n",
            "\n",
            "Let's look at a toy example of square matrix multiplication. We will have the following boilerplate for matrix initilization, printing, and a main function to run them. This main expect a sqmm function, which returns the product of two square matrices.\n",
            "\n",
            "You should probably skip to the next part if you are mainly interested in the GPU kernel example."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "common = \"\"\"\n",
            "\"builtin.module\"() ({\n",
            "\t\"func.func\"() ({}) {\"function_type\" = (memref<?x?xi32>, memref<?x?xi32>, memref<?x?xi32>, index) -> (), \"sym_name\" = \"sqmm\", \"sym_visibility\" = \"private\"} : () -> ()\n",
            "\t\"llvm.func\"() ({}) {\"function_type\" = !llvm.func<i32 (ptr<i8>, ...)>, \"linkage\" = #llvm.linkage<external>, \"sym_name\" = \"printf\"} : () -> ()\n",
            "\t\"memref.global\"() {\"initial_value\" = dense<[37, 56, 100, 32,0]> : tensor<5xi8>, \"sym_name\" = \"format\", \"type\" = memref<5xi8>} : () -> ()\n",
            "\t\"memref.global\"() {\"initial_value\" = dense<[10, 0]> : tensor<2xi8>, \"sym_name\" = \"newline\", \"type\" = memref<2xi8>} : () -> ()\n",
            "\t\"func.func\"() ({\n",
            "\t^body(%A : memref<?x?xi32>, %N : index):\n",
            "\t\t%zero = \"arith.constant\"() {\"value\" = 0 : index} : () -> index\n",
            "        %one = \"arith.constant\"() {\"value\" = 1 : index} : () -> index\n",
            "        %format = \"memref.get_global\"() {\"name\" = @format} : () -> memref<5xi8>\n",
            "\t\t%f0 = \"memref.extract_aligned_pointer_as_index\"(%format) : (memref<5xi8>) -> index\n",
            "\t\t%f1 = \"arith.index_cast\"(%f0) : (index) -> i64\n",
            "\t\t%format_ptr = \"llvm.inttoptr\"(%f1) : (i64) -> !llvm.ptr<i8>\n",
            "        %newline = \"memref.get_global\"() {\"name\" = @newline} : () -> memref<2xi8>\n",
            "\t\t%n0 = \"memref.extract_aligned_pointer_as_index\"(%newline) : (memref<2xi8>) -> index\n",
            "\t\t%n1 = \"arith.index_cast\"(%n0) : (index) -> i64\n",
            "\t\t%newline_ptr = \"llvm.inttoptr\"(%n1) : (i64) -> !llvm.ptr<i8>\n",
            "\t\t\"scf.for\"(%zero, %N, %one) ({\n",
            "\t\t^bb(%i : index):\n",
            "\t\t\t\"scf.for\"(%zero, %N, %one) ({\n",
            "\t\t\t^bb(%j : index):\n",
            "\t\t\t\t%Aij = \"memref.load\"(%A, %i, %j) : (memref<?x?xi32>, index, index) -> i32\n",
            "                %ignored = \"llvm.call\"(%format_ptr, %Aij) {\"callee\" = @printf} : (!llvm.ptr<i8>, i32) -> i32 \n",
            "\t\t\t\t\"scf.yield\"() : () -> ()\n",
            "\t\t\t}) : (index, index, index) -> ()\n",
            "\t\t\t\"llvm.call\"(%newline_ptr) {\"callee\" = @printf} : (!llvm.ptr<i8>) -> i32 \n",
            "\t\t\t\"scf.yield\"() : () -> ()\n",
            "\t\t}) : (index, index, index) -> ()\n",
            "\t\t\"func.return\"() : () -> ()\n",
            "\t}) {\"function_type\" = (memref<?x?xi32>, index) -> (), \"sym_name\" = \"print_mat\"} : () -> ()\n",
            "    \n",
            "\t\"func.func\"() ({\n",
            "\t^body(%A : memref<?x?xi32>, %N : index):\n",
            "\t\t%zero = \"arith.constant\"() {\"value\" = 0 : index} : () -> index\n",
            "        %one = \"arith.constant\"() {\"value\" = 1 : index} : () -> index\n",
            "        %a = \"arith.constant\"() {\"value\" = 3 : index} : () -> index\n",
            "        \n",
            "\t\t\"scf.for\"(%zero, %N, %one) ({\n",
            "\t\t^bb(%i : index):\n",
            "\t\t\t\"scf.for\"(%zero, %N, %one) ({\n",
            "\t\t\t^bb(%j : index):\n",
            "\t\t\t\t%0 = \"arith.muli\"(%i, %a) : (index, index) -> index\n",
            "\t\t\t\t%v = \"arith.addi\"(%0, %j) : (index, index) -> index\n",
            "                %vi = \"index.casts\"(%v) : (index) -> i32\n",
            "\t\t\t\t\"memref.store\"(%vi, %A, %i, %j) : (i32, memref<?x?xi32>, index, index) -> ()\n",
            "\t\t\t\t\"scf.yield\"() : () -> ()\n",
            "\t\t\t}) : (index, index, index) -> ()\n",
            "\t\t\t\"scf.yield\"() : () -> ()\n",
            "\t\t}) : (index, index, index) -> ()\n",
            "\t\t\"func.return\"() : () -> ()\n",
            "\t}) {\"function_type\" = (memref<?x?xi32>, index) -> (), \"sym_name\" = \"init_mat\"} : () -> ()\n",
            "    \n",
            "\t\"func.func\"() ({\n",
            "\t\t%zero = \"arith.constant\"() {\"value\" = 0 : index} : () -> index\n",
            "        %one = \"arith.constant\"() {\"value\" = 1 : index} : () -> index\n",
            "        \n",
            "\t\t%N = \"arith.constant\"() {\"value\" = 2048 : index} : () -> index\n",
            "\t\t%A = \"memref.alloc\"(%N, %N) {\"alignment\" = 8 : i64, \"operand_segment_sizes\" = array<i32:2,0>} : (index, index) -> memref<?x?xi32>\n",
            "\t\t%B = \"memref.alloc\"(%N, %N) {\"alignment\" = 8 : i64, \"operand_segment_sizes\" = array<i32:2,0>} : (index, index) -> memref<?x?xi32>\n",
            "\t\t%C = \"memref.alloc\"(%N, %N) {\"alignment\" = 8 : i64, \"operand_segment_sizes\" = array<i32:2,0>} : (index, index) -> memref<?x?xi32>\n",
            "        \n",
            "        \"func.call\"(%A, %N) {\"callee\" = @init_mat} : (memref<?x?xi32>, index) -> ()\n",
            "        \"func.call\"(%B, %N) {\"callee\" = @init_mat} : (memref<?x?xi32>, index) -> ()\n",
            "        \"func.call\"(%C, %A, %B, %N) {\"callee\" = @sqmm} : (memref<?x?xi32>, memref<?x?xi32>, memref<?x?xi32>, index) -> ()\n",
            "        \"func.call\"(%C, %N) {\"callee\" = @print_mat} : (memref<?x?xi32>, index) -> ()\n",
            "        \n",
            "        \n",
            "\t\t\"memref.dealloc\"(%A) : (memref<?x?xi32>) -> ()\n",
            "\t\t\"memref.dealloc\"(%B) : (memref<?x?xi32>) -> ()\n",
            "\t\t\"memref.dealloc\"(%C) : (memref<?x?xi32>) -> ()\n",
            "\t\t\"func.return\"(%zero) : (index) -> ()\n",
            "\t}) {\"function_type\" = () -> (index), \"sym_name\" = \"main\"} : () -> ()\n",
            "}) : () -> ()\n",
            "\"\"\""
         ]
      },
      {
         "attachments": {},
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Let's compile the boilerplate to an object, to link with our multiplication kernels later."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "!echo '{common}' | mlir-opt - -test-lower-to-llvm | mlir-translate - --mlir-to-llvmir | clang -x ir -c - -o /tmp/common.o"
         ]
      },
      {
         "attachments": {},
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Now, let's look at a naive, CPU-only implementation:"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "#Here is some non-GPU stuff:\n",
            "non_gpu = \"\"\"\n",
            "\"builtin.module\"() ({\n",
            "\t\"func.func\"() ({}) {\"function_type\" = (memref<?x?xi32>, index) -> (), \"sym_name\" = \"print_mat\", \"sym_visibility\" = \"private\"} : () -> ()\n",
            "\t\"func.func\"() ({}) {\"function_type\" = (memref<?x?xi32>, index) -> (), \"sym_name\" = \"init_mat\", \"sym_visibility\" = \"private\"} : () -> ()\n",
            "\t\"func.func\"() ({\n",
            "\t^body(%C : memref<?x?xi32>, %A : memref<?x?xi32>, %B : memref<?x?xi32>, %N : index):\n",
            "\t\t%zero = \"arith.constant\"() {\"value\" = 0 : index} : () -> index\n",
            "\t\t%zeroi = \"arith.constant\"() {\"value\" = 0 : i32} : () -> i32\n",
            "        %one = \"arith.constant\"() {\"value\" = 1 : index} : () -> index\n",
            "        \n",
            "\t\t\"scf.for\"(%zero, %N, %one) ({\n",
            "\t\t^bb(%i : index):\n",
            "\t\t\t\"scf.for\"(%zero, %N, %one) ({\n",
            "\t\t\t^bb(%j : index):\n",
            "\t\t\t\t%Cij = \"scf.for\"(%zero, %N, %one, %zeroi) ({\n",
            "\t\t\t\t^bb(%k : index, %sum : i32):\n",
            "\t\t\t\t\t%Aij = \"memref.load\"(%A, %i, %j) : (memref<?x?xi32>, index, index) -> i32\n",
            "\t\t\t\t\t%Bij = \"memref.load\"(%B, %i, %j) : (memref<?x?xi32>, index, index) -> i32\n",
            "                    %prodk = \"arith.muli\"(%Aij, %Bij) : (i32, i32) -> i32\n",
            "                    %new_sum = \"arith.addi\"(%sum, %prodk) : (i32, i32) -> i32\n",
            "\t\t\t\t\t\"scf.yield\"(%new_sum) : (i32) -> ()\n",
            "\t\t\t\t}) : (index, index, index, i32) -> i32\n",
            "\t\t\t\t\"memref.store\"(%Cij, %C, %i, %j) : (i32, memref<?x?xi32>, index, index) -> ()\n",
            "\t\t\t\t\"scf.yield\"() : () -> ()\n",
            "\t\t\t}) : (index, index, index) -> ()\n",
            "\t\t\t\"scf.yield\"() : () -> ()\n",
            "\t\t}) : (index, index, index) -> ()\n",
            "\t\t\"func.return\"() : () -> ()\n",
            "\t}) {\"function_type\" = (memref<?x?xi32>, memref<?x?xi32>, memref<?x?xi32>, index) -> (), \"sym_name\" = \"sqmm\"} : () -> ()\n",
            "}) {} : () -> ()\n",
            "\"\"\""
         ]
      },
      {
         "attachments": {},
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "We can compile it to an object file, and compile an executable by linking it to the boilerplate this way:"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "!echo '{non_gpu}' | xdsl-opt -f mlir -t mlir | mlir-opt --test-lower-to-llvm | mlir-translate --mlir-to-llvmir | clang -x ir -o /tmp/non_gpu.o -c -\n",
            "!clang /tmp/non_gpu.o /tmp/common.o -o /tmp/non_gpu"
         ]
      },
      {
         "attachments": {},
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Let's see how it runs:"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "!time /tmp/non_gpu > /tmp/non_gpu_output"
         ]
      },
      {
         "attachments": {},
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "That's not great. Let's implement that on a GPU:"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "#Here is some non-GPU stuff:\n",
            "gpu_stuff = \"\"\"\n",
            "\"builtin.module\"() ({\n",
            "\t\"func.func\"() ({}) {\"function_type\" = (memref<?x?xi32>, index) -> (), \"sym_name\" = \"print_mat\", \"sym_visibility\" = \"private\"} : () -> ()\n",
            "\t\"func.func\"() ({}) {\"function_type\" = (memref<?x?xi32>, index) -> (), \"sym_name\" = \"init_mat\", \"sym_visibility\" = \"private\"} : () -> ()\n",
            "\t\"func.func\"() ({\n",
            "\t^body(%C : memref<?x?xi32>, %A : memref<?x?xi32>, %B : memref<?x?xi32>, %N : index):\n",
            "\t\t%zero = \"arith.constant\"() {\"value\" = 0 : index} : () -> index\n",
            "        %one = \"arith.constant\"() {\"value\" = 1 : index} : () -> index\n",
            "\t\t%zeroi = \"arith.constant\"() {\"value\" = 0 : i32} : () -> i32\n",
            "        %32 = \"arith.constant\"() {\"value\" = 32 : index} : () -> index\n",
            "        %blocks = \"arith.ceildivui\"(%N, %32) : (index, index) -> index\n",
            "        %uA = \"memref.cast\"(%A) : (memref<?x?xi32>) -> memref<*xi32>\n",
            "        %uB = \"memref.cast\"(%B) : (memref<?x?xi32>) -> memref<*xi32>\n",
            "        %uC = \"memref.cast\"(%C) : (memref<?x?xi32>) -> memref<*xi32>\n",
            "        \"gpu.host_register\"(%uA) : (memref<*xi32>) -> ()\n",
            "        \"gpu.host_register\"(%uB) : (memref<*xi32>) -> ()\n",
            "        \"gpu.host_register\"(%uC) : (memref<*xi32>) -> ()\n",
            "        \"gpu.launch\"(%blocks, %blocks, %one, %32, %32, %one) ({\n",
            "\t\t^bb0(%bx : index, %by : index, %bz : index,\n",
            "\t\t\t %tx : index, %ty : index, %tz : index,\n",
            "\t\t\t %num_bx : index, %num_by : index, %num_bz : index,\n",
            "\t\t\t %num_tx : index, %num_ty : index, %num_tz : index):\n",
            "             \n",
            "             \n",
            "             %bi = \"arith.muli\"(%bx, %num_tx) : (index, index) -> index\n",
            "             %bj = \"arith.muli\"(%by, %num_ty) : (index, index) -> index\n",
            "             %i = \"arith.addi\"(%bi, %tx) : (index, index) -> index\n",
            "             %j = \"arith.addi\"(%bj, %ty) : (index, index) -> index\n",
            "             \n",
            "        \t%one2 = \"arith.constant\"() {\"value\" = 1 : index} : () -> index\n",
            "\t\t\t%Cij = \"scf.for\"(%zero, %N, %one2, %zeroi) ({\n",
            "\t\t\t^bb(%k : index, %sum : i32):\n",
            "\t\t\t\t%Aij = \"memref.load\"(%A, %i, %j) : (memref<?x?xi32>, index, index) -> i32\n",
            "\t\t\t\t%Bij = \"memref.load\"(%B, %i, %j) : (memref<?x?xi32>, index, index) -> i32\n",
            "\t\t\t\t%prodk = \"arith.muli\"(%Aij, %Bij) : (i32, i32) -> i32\n",
            "\t\t\t\t%new_sum = \"arith.addi\"(%sum, %prodk) : (i32, i32) -> i32\n",
            "\t\t\t\t\"scf.yield\"(%new_sum) : (i32) -> ()\n",
            "\t\t\t}) : (index, index, index, i32) -> i32\n",
            "\t\t\t\"memref.store\"(%Cij, %C, %i, %j) : (i32, memref<?x?xi32>, index, index) -> ()\n",
            "\t\t\t\"gpu.terminator\"() : () -> ()\n",
            "\t\t}) {\"operand_segment_sizes\" = array<i32: 0, 1, 1, 1, 1, 1, 1, 0>} : (index, index, index, index, index, index) -> () \n",
            "\t\t\"func.return\"() : () -> ()\n",
            "\t}) {\"function_type\" = (memref<?x?xi32>, memref<?x?xi32>, memref<?x?xi32>, index) -> (), \"sym_name\" = \"sqmm\"} : () -> ()\n",
            "}) {} : () -> ()\n",
            "\"\"\""
         ]
      },
      {
         "attachments": {},
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "We can compile it to an object file, and compile an executable by linking it to the boilerplate this way:"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "!echo '{gpu_stuff}' | xdsl-opt -f mlir -t mlir | mlir-opt --pass-pipeline=\"builtin.module(gpu-kernel-outlining, convert-scf-to-cf, gpu.module(convert-gpu-to-nvvm, reconcile-unrealized-casts, symbol-dce, gpu-to-cubin), gpu-to-llvm, arith-expand, convert-arith-to-llvm, convert-index-to-llvm, reconcile-unrealized-casts, symbol-dce)\" | mlir-translate --mlir-to-llvmir | clang -x ir -c -o /tmp/gpu.o -c -\n",
            "!clang /tmp/gpu.o /tmp/common.o -o /tmp/gpu -lmlir_cuda_runtime"
         ]
      },
      {
         "attachments": {},
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "And run it:"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "!time /tmp/gpu > /tmp/gpu_output"
         ]
      },
      {
         "attachments": {},
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Check that the results were the same:"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "!if diff /tmp/gpu_output /tmp/non_gpu_output; then echo \"Outputs are the same!\"; else echo \"Outputs are different!\"; fi"
         ]
      },
      {
         "attachments": {},
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Et voil√†, a naive GPU kernel hopefully giving some speedup!"
         ]
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": "venv",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.10.7"
      },
      "orig_nbformat": 4
   },
   "nbformat": 4,
   "nbformat_minor": 2
}
