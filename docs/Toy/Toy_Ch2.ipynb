{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "56341c66",
   "metadata": {},
   "source": [
    "# Chapter 2: Emitting Basic MLIR\n",
    "\n",
    "Now that we're familiar with our language and the AST, let's see how MLIR can\n",
    "help to compile Toy.\n",
    "\n",
    "## Introduction: Multi-Level Intermediate Representation\n",
    "\n",
    "Other compilers, like LLVM (see the\n",
    "[Kaleidoscope tutorial](https://llvm.org/docs/tutorial/MyFirstLanguageFrontend/index.html)),\n",
    "offer a fixed set of predefined types and (usually *low-level* / RISC-like)\n",
    "instructions. It is up to the frontend for a given language to perform any\n",
    "language-specific type-checking, analysis, or transformation before emitting\n",
    "LLVM IR. For example, Clang will use its AST to perform not only static analysis\n",
    "but also transformations, such as C++ template instantiation through AST cloning\n",
    "and rewrite. Finally, languages with construction at a higher-level than C/C++\n",
    "may require non-trivial lowering from their AST to generate LLVM IR.\n",
    "\n",
    "As a consequence, multiple frontends end up reimplementing significant pieces of\n",
    "infrastructure to support the need for these analyses and transformation. MLIR\n",
    "addresses this issue by being designed for extensibility. As such, there are few\n",
    "pre-defined instructions (*operations* in MLIR terminology) or types.\n",
    "\n",
    "## Interfacing with MLIR\n",
    "\n",
    "MLIR is designed to be a completely extensible infrastructure; there is no\n",
    "closed set of attributes (think: constant metadata), operations, or types. MLIR\n",
    "supports this extensibility with the concept of Dialects. Dialects provide a grouping \n",
    "mechanism for abstraction under a unique `namespace`.\n",
    "\n",
    "In MLIR, `Operations` are the core unit of abstraction and computation, similar in many \n",
    "ways to LLVM instructions. Operations can have application-specific semantics and can be \n",
    "used to represent all of the core IR structures in LLVM: instructions, globals (like \n",
    "functions), modules, etc.\n",
    "\n",
    "Here is the MLIR assembly for the Toy `transpose` operations:\n",
    "\n",
    "```mlir\n",
    "%t_tensor = \"toy.transpose\"(%tensor) {inplace = true} : (tensor<2x3xf64>) -> tensor<3x2xf64> loc(\"example/file/path\":12:1)\n",
    "```\n",
    "\n",
    "Let's break down the anatomy of this MLIR operation:\n",
    "\n",
    "-   `%t_tensor`\n",
    "\n",
    "    *   The name given to the result defined by this operation (which includes\n",
    "        [a prefixed sigil to avoid collisions](../../LangRef.md/#identifiers-and-keywords)).\n",
    "        An operation may define zero or more results (in the context of Toy, we\n",
    "        will limit ourselves to single-result operations), which are SSA values.\n",
    "        The name is used during parsing but is not persistent (e.g., it is not\n",
    "        tracked in the in-memory representation of the SSA value).\n",
    "\n",
    "-   `\"toy.transpose\"`\n",
    "\n",
    "    *   The name of the operation. It is expected to be a unique string, with\n",
    "        the namespace of the dialect prefixed before the \"`.`\". This can be read\n",
    "        as the `transpose` operation in the `toy` dialect.\n",
    "\n",
    "-   `(%tensor)`\n",
    "\n",
    "    *   A list of zero or more input operands (or arguments), which are SSA\n",
    "        values defined by other operations or referring to block arguments.\n",
    "\n",
    "-   `{ inplace = true }`\n",
    "\n",
    "    *   A dictionary of zero or more attributes, which are special operands that\n",
    "        are always constant. Here we define a boolean attribute named 'inplace'\n",
    "        that has a constant value of true.\n",
    "\n",
    "-   `(tensor<2x3xf64>) -> tensor<3x2xf64>`\n",
    "\n",
    "    *   This refers to the type of the operation in a functional form, spelling\n",
    "        the types of the arguments in parentheses and the type of the return\n",
    "        values afterward.\n",
    "\n",
    "-   `loc(\"example/file/path\":12:1)`\n",
    "\n",
    "    *   This is the location in the source code from which this operation\n",
    "        originated.\n",
    "\n",
    "Shown here is the general form of an operation. As described above,\n",
    "the set of operations in MLIR is extensible. Operations are modeled\n",
    "using a small set of concepts, enabling operations to be reasoned\n",
    "about and manipulated generically. These concepts are:\n",
    "\n",
    "-   A name for the operation.\n",
    "-   A list of SSA operand values.\n",
    "-   A list of attributes.\n",
    "-   A list of types for result values.\n",
    "-   A source location for debugging purposes.\n",
    "-   A list of successors blocks (for branches, mostly).\n",
    "-   A list of regions (for structural operations like functions).\n",
    "\n",
    "In MLIR, every operation has a mandatory source location associated with it.\n",
    "Contrary to LLVM, where debug info locations are metadata and can be dropped, in\n",
    "MLIR, the location is a core requirement, and APIs depend on and manipulate it.\n",
    "Dropping a location is thus an explicit choice which cannot happen by mistake.\n",
    "\n",
    "To provide an illustration: If a transformation replaces an operation by\n",
    "another, that new operation must still have a location attached. This makes it\n",
    "possible to track where that operation came from.\n",
    "\n",
    "It's worth noting that the mlir-opt tool - a tool for testing\n",
    "compiler passes - does not include locations in the output by default. The\n",
    "`-mlir-print-debuginfo` flag specifies to include locations. (Run `mlir-opt\n",
    "--help` for more options.)\n",
    "\n",
    "### Opaque API\n",
    "\n",
    "MLIR is designed to allow all IR elements, such as attributes, operations, and\n",
    "types, to be customized. At the same time, IR elements can always be reduced to\n",
    "the above fundamental concepts. This allows MLIR to parse, represent, and\n",
    "round-trip IR for *any*\n",
    "operation. For example, we could place our Toy operation from above into an\n",
    "`.mlir` file and round-trip through *mlir-opt* without registering any `toy`\n",
    "related dialect:\n",
    "\n",
    "```mlir\n",
    "func @toy_func(%tensor: tensor<2x3xf64>) -> tensor<3x2xf64> {\n",
    "  %t_tensor = \"toy.transpose\"(%tensor) { inplace = true } : (tensor<2x3xf64>) -> tensor<3x2xf64>\n",
    "  return %t_tensor : tensor<3x2xf64>\n",
    "}\n",
    "```\n",
    "\n",
    "In the cases of unregistered attributes, operations, and types, MLIR will\n",
    "enforce some structural constraints (e.g. dominance, etc.), but otherwise they\n",
    "are completely opaque. For instance, MLIR has little information about whether\n",
    "an unregistered operation can operate on particular data types, how many\n",
    "operands it can take, or how many results it produces. This flexibility can be\n",
    "useful for bootstrapping purposes, but it is generally advised against in mature\n",
    "systems. Unregistered operations must be treated conservatively by\n",
    "transformations and analyses, and they are much harder to construct and\n",
    "manipulate.\n",
    "\n",
    "This handling can be observed by crafting what should be an invalid IR for Toy\n",
    "and seeing it round-trip without tripping the verifier:\n",
    "\n",
    "```mlir\n",
    "func @main() {\n",
    "  %0 = \"toy.print\"() : () -> tensor<2x3xf64>\n",
    "}\n",
    "```\n",
    "\n",
    "There are multiple problems here: the `toy.print` operation is not a terminator;\n",
    "it should take an operand; and it shouldn't return any values. In the next\n",
    "section, we will register our dialect and operations with MLIR, plug into the\n",
    "verifier, and add nicer APIs to manipulate our operations.\n",
    "\n",
    "\n",
    "## Defining Toy Operations\n",
    "\n",
    "Now that we have a `Toy` dialect, we can start defining the operations. This\n",
    "will allow for providing semantic information that the rest of the system can\n",
    "hook into. As an example, let's walk through the creation of a `toy.constant`\n",
    "operation. This operation will represent a constant value in the Toy language.\n",
    "\n",
    "```mlir\n",
    " %4 = \"toy.constant\"() {value = dense<1.0> : tensor<2x3xf64>} : () -> tensor<2x3xf64>\n",
    "```\n",
    "\n",
    "This operation takes zero operands, a dense elements attribute named `value` \n",
    "to represent the constant value, and returns a single result of RankedTensorType. \n",
    "Let's take a look at the full definition and step through it in detail.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96c2a0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from xdsl.dialects.builtin import TensorType, f64, DenseIntOrFPElementsAttr\n",
    "from xdsl.irdl import IRDLOperation, OpAttr, irdl_op_definition, OpResult\n",
    "from xdsl.utils.exceptions import VerifyException\n",
    "\n",
    "from toy.dialects import toy\n",
    "\n",
    "@irdl_op_definition\n",
    "class ConstantOp(IRDLOperation):\n",
    "    '''\n",
    "    Constant operation turns a literal into an SSA value. The data is attached\n",
    "    to the operation as an attribute. For example:\n",
    "\n",
    "      %0 = toy.constant dense<[[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]]>\n",
    "                        : tensor<2x3xf64>\n",
    "    '''\n",
    "    name: str = \"toy.constant\"\n",
    "    value: OpAttr[DenseIntOrFPElementsAttr]\n",
    "    res: Annotated[OpResult, toy.TensorTypeF64]\n",
    "\n",
    "    @staticmethod\n",
    "    def from_list(data: list[float], shape: list[int]):\n",
    "        value = DenseIntOrFPElementsAttr.tensor_from_list(data, f64, shape)\n",
    "\n",
    "        return ConstantOp.create(result_types=[value.type],\n",
    "                                 attributes={\"value\": value})\n",
    "\n",
    "    def verify_(self) -> None:\n",
    "        resultType = self.res.typ\n",
    "        value = self.value\n",
    "        if not isinstance(resultType, TensorType):\n",
    "            raise VerifyException(\"Expected result type to be `TensorTypeF64`\")\n",
    "\n",
    "        if not isinstance(value, DenseIntOrFPElementsAttr):\n",
    "            raise VerifyException(\n",
    "                \"Expected value type to be instance of `DenseIntOrFPElementsAttr`\"\n",
    "            )\n",
    "\n",
    "        if resultType.get_shape() != value.shape:\n",
    "            raise VerifyException(\n",
    "                \"Expected value and result to have the same shape\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f9e6cbdb",
   "metadata": {},
   "source": [
    "### The Operation base class\n",
    "\n",
    "Each operation subclasses the `Operation` class, and are prefixed by the \n",
    "`@irdl_op_definition` decorator. The decorator steps through the definition of the\n",
    "operation, and connverts it into a canonical form that the compilation engine can use.\n",
    "Each operation must have a `name` of type `str`, and the name must be composed of the name\n",
    "of the dialect, in this case `toy`, followed by a unique name of the operation. The name\n",
    "is followed by the fields of the operation, along with their constraints.\n",
    "\n",
    "### Operation fields\n",
    "\n",
    "An operation is composed of operands, attributes, and results. In the case of the constant\n",
    "operation, there is no input, a single attribute containing the initial value for the\n",
    "variable, and a result containing the SSA value of the variable itself. Here is the format\n",
    "for operation field definitions:\n",
    "\n",
    "``` python\n",
    "@irdl_op_definition\n",
    "class MyOp(Operation):\n",
    "  name: 'my_dialect.my_op'\n",
    "\n",
    "  # Normal attribute field, conforming to MyAttributeConstraint\n",
    "  my_attribute: OpAttr[MyAttributeConstraint] \n",
    "  # Optional attribute field\n",
    "  optional_attribute: OptOpAttr[MyAttributeConstraint]\n",
    "  # Variadic attribute field\n",
    "  variadic_attribute: VarOpAttr[MyAttributeConstraint]\n",
    "\n",
    "  # Normal operand field, conforming to MyOperandConstraint\n",
    "  my_operand: Annotated[Operand, MyOperandConstraint] \n",
    "  # Optional operand field\n",
    "  optional_attribute: Annotated[OptOperand, MyOperandConstraint]\n",
    "  # Variadic operand field\n",
    "  variadic_attribute: Annotated[VarOperand, MyOperandConstraint]\n",
    "\n",
    "  # Normal result field, conforming to MyResultConstraint\n",
    "  my_result: Annotated[OpResult, MyResultConstraint]\n",
    "  # Optional result field\n",
    "  optional_result: Annotated[OptOpResult, MyResultConstraint]\n",
    "  # Variadic result field\n",
    "  variadic_result: Annotated[VarOpResult, MyResultConstraint]\n",
    "```\n",
    "\n",
    "Please see `dialect.py` for the definitions of other operations in the dialect, which\n",
    "use these constructs.\n",
    "\n",
    "### Constructor helper\n",
    "\n",
    "```\n",
    "    @staticmethod\n",
    "    def from_list(data: list[float], shape: list[int]):\n",
    "        value = DenseIntOrFPElementsAttr.tensor_from_list(data, f64, shape)\n",
    "\n",
    "        return ConstantOp.create(result_types=[value.type],\n",
    "                                 attributes={\"value\": value})\n",
    "```\n",
    "\n",
    "Operations tend to have helper methods for constructing them, that call into the generic\n",
    "constructors on the Operation class. In this case, the client passes in a flat python\n",
    "`list` of `float`s for the data, and a shape definition. These get converted to the\n",
    "attribute and result type that the `create` method expects as input.\n",
    "\n",
    "### Custom verifier\n",
    "\n",
    "``` python\n",
    "    def verify_(self) -> None:\n",
    "        resultType = self.res.typ\n",
    "        value = self.value\n",
    "        if not isinstance(resultType, TensorType):\n",
    "            raise VerifyException(\"Expected result type to be `TensorTypeF64`\")\n",
    "\n",
    "        if not isinstance(value, DenseIntOrFPElementsAttr):\n",
    "            raise VerifyException(\n",
    "                \"Expected value type to be instance of `DenseIntOrFPElementsAttr`\"\n",
    "            )\n",
    "\n",
    "        if resultType.get_shape() != value.shape:\n",
    "            raise VerifyException(\n",
    "                \"Expected value and result to have the same shape\")\n",
    "```\n",
    "\n",
    "One thing to notice here is that all of our Toy operations are printed using the\n",
    "generic assembly format. This format is the one shown when breaking down\n",
    "`toy.transpose` at the beginning of this chapter. MLIR allows for operations to\n",
    "define their own custom assembly format, either or imperatively via C++. Defining a custom \n",
    "assembly format allows for tailoring the generated IR into something a bit more readable \n",
    "by removing a lot of the fluff that is required by the generic format. Let's walk through \n",
    "an example of an operation format that we would like to simplify.\n",
    "\n",
    "This capability will soon be added to xDSL also, and will be interoperable with the MLIR\n",
    "format definitions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f24f9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xdsl.ir import MLContext\n",
    "from xdsl.printer import Printer\n",
    "\n",
    "# MLContext, containing information about the registered dialects\n",
    "ctx = MLContext()\n",
    "\n",
    "ctx.register_dialect(toy.Toy)\n",
    "\n",
    "printer = Printer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82230c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"builtin.module\"() ({\n",
      "  \"toy.func\"() ({\n",
      "  ^0(%0 : tensor<*xf64>, %1 : tensor<*xf64>):\n",
      "    %2 = \"toy.transpose\"(%0) : (tensor<*xf64>) -> tensor<*xf64>\n",
      "    %3 = \"toy.transpose\"(%1) : (tensor<*xf64>) -> tensor<*xf64>\n",
      "    %4 = \"toy.mul\"(%2, %3) : (tensor<*xf64>, tensor<*xf64>) -> tensor<*xf64>\n",
      "    \"toy.return\"(%4) : (tensor<*xf64>) -> ()\n",
      "  }) {\"sym_name\" = \"multiply_transpose\", \"function_type\" = (tensor<*xf64>, tensor<*xf64>) -> tensor<*xf64>, \"sym_visibility\" = \"private\"} : () -> ()\n",
      "  \"toy.func\"() ({\n",
      "    %5 = \"toy.constant\"() {\"value\" = dense<[[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]]> : tensor<2x3xf64>} : () -> tensor<2x3xf64>\n",
      "    %6 = \"toy.constant\"() {\"value\" = dense<[1.0, 2.0, 3.0, 4.0, 5.0, 6.0]> : tensor<6xf64>} : () -> tensor<6xf64>\n",
      "    %7 = \"toy.reshape\"(%6) : (tensor<6xf64>) -> tensor<2x3xf64>\n",
      "    %8 = \"toy.generic_call\"(%5, %7) {\"callee\" = @multiply_transpose} : (tensor<2x3xf64>, tensor<2x3xf64>) -> tensor<*xf64>\n",
      "    %9 = \"toy.generic_call\"(%7, %5) {\"callee\" = @multiply_transpose} : (tensor<2x3xf64>, tensor<2x3xf64>) -> tensor<*xf64>\n",
      "    %10 = \"toy.generic_call\"(%7, %8) {\"callee\" = @multiply_transpose} : (tensor<2x3xf64>, tensor<*xf64>) -> tensor<*xf64>\n",
      "    %11 = \"toy.transpose\"(%5) : (tensor<2x3xf64>) -> tensor<3x2xf64>\n",
      "    %12 = \"toy.generic_call\"(%11, %8) {\"callee\" = @multiply_transpose} : (tensor<3x2xf64>, tensor<*xf64>) -> tensor<*xf64>\n",
      "    \"toy.return\"() : () -> ()\n",
      "  }) {\"sym_name\" = \"main\", \"function_type\" = () -> ()} : () -> ()\n",
      "}) : () -> ()\n"
     ]
    }
   ],
   "source": [
    "from xdsl.ir import SSAValue, BlockArgument, OpResult\n",
    "from xdsl.dialects.builtin import ModuleOp, f64, FunctionType\n",
    "from xdsl.builder import Builder\n",
    "\n",
    "\n",
    "@ModuleOp\n",
    "@Builder.implicit_region\n",
    "def module_op():\n",
    "    unrankedf64TensorType = toy.UnrankedTensorType.from_type(f64)\n",
    "\n",
    "    multiply_transpose_type = FunctionType.from_lists(\n",
    "        [unrankedf64TensorType, unrankedf64TensorType],\n",
    "        [unrankedf64TensorType])\n",
    "\n",
    "    @Builder.implicit_region(multiply_transpose_type.inputs)\n",
    "    def multiply_transpose(args: tuple[BlockArgument, ...]) -> None:\n",
    "        a, b = args\n",
    "        a_t = toy.TransposeOp(a).res\n",
    "        b_t = toy.TransposeOp(b).res\n",
    "        prod = toy.MulOp(a_t, b_t).res\n",
    "        toy.ReturnOp(prod)\n",
    "\n",
    "    def call_multiply_transpose(a: SSAValue, b: SSAValue) -> OpResult:\n",
    "        return toy.GenericCallOp(\"multiply_transpose\", [a, b],\n",
    "                                 [unrankedf64TensorType]).res[0]\n",
    "\n",
    "    main_type = FunctionType.from_lists([], [])\n",
    "\n",
    "    @Builder.implicit_region\n",
    "    def main() -> None:\n",
    "        a = toy.ConstantOp.from_list([1, 2, 3, 4, 5, 6], [2, 3]).res\n",
    "        b_0 = toy.ConstantOp.from_list([1, 2, 3, 4, 5, 6], [6]).res\n",
    "        b = toy.ReshapeOp(b_0, [2, 3]).res\n",
    "        c = call_multiply_transpose(a, b)\n",
    "        call_multiply_transpose(b, a)\n",
    "        call_multiply_transpose(b, c)\n",
    "        a_t = toy.TransposeOp(a).res\n",
    "        call_multiply_transpose(a_t, c)\n",
    "        toy.ReturnOp()\n",
    "\n",
    "    toy.FuncOp(\"multiply_transpose\",\n",
    "               multiply_transpose_type,\n",
    "               multiply_transpose,\n",
    "               private=True)\n",
    "    toy.FuncOp(\"main\", main_type, main)\n",
    "\n",
    "\n",
    "printer.print(module_op)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
