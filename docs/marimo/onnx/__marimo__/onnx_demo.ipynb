{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "Hbol",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "# ONNX to Snitch\n",
    "\n",
    "This notebook uses Marimo, a Jupyter-like notebook with interactive UI elements and reactive state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MJUe",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"markdown prose dark:prose-invert\"><span class=\"paragraph\">For example, here is a slider, which can take on values from 1 to 4.</span>\n",
       "<span class=\"paragraph\"><marimo-ui-element object-id='MJUe-0' random-id='bdd640fb-0667-1ad1-1c80-317fa3b1799d'><marimo-slider data-initial-value='2' data-label='&quot;&lt;span class=&#92;&quot;markdown prose dark:prose-invert&#92;&quot;&gt;&lt;span class=&#92;&quot;paragraph&#92;&quot;&gt;Rank&lt;/span&gt;&lt;/span&gt;&quot;' data-start='1' data-stop='4' data-steps='[]' data-debounce='false' data-orientation='&quot;horizontal&quot;' data-show-value='false' data-full-width='false'></marimo-slider></marimo-ui-element></span></span>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rank = mo.ui.slider(1, 4, value=2, label=\"Rank\")\n",
    "\n",
    "mo.md(\n",
    "    f\"\"\"\n",
    "    For example, here is a slider, which can take on values from 1 to 4.\n",
    "\n",
    "    {rank}\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vblA",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"markdown prose dark:prose-invert\"><span class=\"paragraph\">We use the slider to determine the shape of our inputs and outputs:</span>\n",
       "<div class=\"codehilite\"><pre><span></span><code>A: 2x3xf64\n",
       "B: 2x3xf64\n",
       "C: 2x3xf64\n",
       "</code></pre></div></span>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "shape = tuple(range(2, 2 + rank.value))\n",
    "\n",
    "mo.md(\n",
    "    f\"\"\"\n",
    "    We use the slider to determine the shape of our inputs and outputs:\n",
    "\n",
    "    ```\n",
    "    A: {'x'.join(str(dim) for dim in shape)}xf64\n",
    "    B: {'x'.join(str(dim) for dim in shape)}xf64\n",
    "    C: {'x'.join(str(dim) for dim in shape)}xf64\n",
    "    ```\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bkHC",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"markdown prose dark:prose-invert\"><h3 id=\"the-onnx-model\">The ONNX model</h3>\n",
       "<span class=\"paragraph\">We use the ONNX API to build a simple function, one that returns the elementwise sum of two arrays of shape (2, 3)</span></span>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mo.md(\n",
    "    f\"\"\"\n",
    "    ### The ONNX model\n",
    "\n",
    "    We use the ONNX API to build a simple function, one that returns the elementwise sum of two arrays of shape {shape}\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lEQa",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<span class=\"codehilite\"><div class=\"highlight\"><pre><span></span><span class=\"gt\">Traceback (most recent call last):</span>\n",
      "  File <span class=\"nb\">&quot;/Users/sasha/Developer/xdslproject/xdsl/.venv/lib/python3.12/site-packages/marimo/_runtime/executor.py&quot;</span>, line <span class=\"m\">141</span>, in <span class=\"n\">execute_cell</span>\n",
      "<span class=\"w\">    </span><span class=\"n\">exec</span><span class=\"p\">(</span><span class=\"n\">cell</span><span class=\"o\">.</span><span class=\"n\">body</span><span class=\"p\">,</span> <span class=\"n\">glbls</span><span class=\"p\">)</span>\n",
      "  File <span class=\"nb\">&quot;/var/folders/84/ql679qw90tdc6pkg78v59jl40000gn/T/marimo_84608/__marimo__cell_lEQa_.py&quot;</span>, line <span class=\"m\">1</span>, in <span class=\"n\">&lt;module&gt;</span>\n",
      "<span class=\"w\">    </span><span class=\"kn\">import</span><span class=\"w\"> </span><span class=\"nn\">onnx</span>\n",
      "<span class=\"gr\">ModuleNotFoundError</span>: <span class=\"n\">No module named &#39;onnx&#39;</span>\n",
      "</pre></div>\n",
      "</span>"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "from onnx import AttributeProto, GraphProto, TensorProto, ValueInfoProto, helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PKri",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create one input (ValueInfoProto)\n",
    "X1 = helper.make_tensor_value_info(\"X1\", TensorProto.DOUBLE, shape)\n",
    "X2 = helper.make_tensor_value_info(\"X2\", TensorProto.DOUBLE, shape)\n",
    "\n",
    "# Create one output (ValueInfoProto)\n",
    "Y = helper.make_tensor_value_info(\"Y\", TensorProto.DOUBLE, shape)\n",
    "\n",
    "# Create a node (NodeProto) - This is based on Pad-11\n",
    "node_def = helper.make_node(\n",
    "    \"Sub\",  # node name\n",
    "    [\"X1\", \"X2\"],  # inputs\n",
    "    [\"Y\"],  # outputs\n",
    ")\n",
    "\n",
    "# Create the graph (GraphProto)\n",
    "graph_def = helper.make_graph(\n",
    "    [node_def],\n",
    "    \"main_graph\",\n",
    "    [X1, X2],\n",
    "    [Y],\n",
    ")\n",
    "\n",
    "# Set opset version to 18\n",
    "opset_import = [helper.make_operatorsetid(\"\", 18)]\n",
    "\n",
    "# Create the model (ModelProto) without using helper.make_model\n",
    "model_def = helper.make_model(\n",
    "    graph_def, producer_name=\"onnx-example\", opset_imports=opset_import\n",
    ")\n",
    "\n",
    "onnx.checker.check_model(model_def)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Xref",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "ONNX uses a serialized binary format for neural networks, but can also print a string format, which can be useful for debugging.\n",
    "Here is the textual format of our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SFPL",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "outputs": [],
   "source": [
    "mo.accordion(\n",
    "    {\n",
    "        \"ONNX Graph\": mo.plain_text(f\"{model_def}\"),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BYtC",
   "metadata": {},
   "outputs": [],
   "source": [
    "mo.md(f\"\"\"\n",
    "### Converting to `linalg`\n",
    "\n",
    "Here is the xDSL representation of the function, it takes two `tensor` values of our chosen shape, passes them as operands to the `onnx.Add` operation, and returns it:\n",
    "\n",
    "{xmo.module_html(init_module)}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RGSE",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_module = build_module(model_def.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Kclp",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "outputs": [],
   "source": [
    "ctx = MLContext()\n",
    "\n",
    "for dialect_name, dialect_factory in get_all_dialects().items():\n",
    "    ctx.register_dialect(dialect_name, dialect_factory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emfo",
   "metadata": {},
   "source": [
    "xDSL seamlessly interoperates with MLIR, we the `mlir-opt` tool to compile the input to a form that we want to process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Hstk",
   "metadata": {},
   "outputs": [],
   "source": [
    "bufferized_ctx, bufferized_module, linalg_html = xmo.pipeline_html(\n",
    "    ctx,\n",
    "    init_module,\n",
    "    (\n",
    "        (\n",
    "            mo.md(\n",
    "                \"\"\"\\\n",
    "We can use a pass implemented in xDSL to convert the ONNX operations to builtin operations, here we can use the `tensor.empty` op to create our output buffer, and `linalg.add` to represent the addition in destination-passing style:\n",
    "\"\"\"\n",
    "            ),\n",
    "            ConvertOnnxToLinalgPass()\n",
    "        ),\n",
    "        (\n",
    "            mo.md(\n",
    "                \"\"\"\n",
    "We can also call into MLIR, here to convert `linalg.add` to `linalg.generic`, a representation of Einstein summation:\n",
    "\"\"\"\n",
    "            ),\n",
    "            MLIROptPass(\n",
    "                generic=False,\n",
    "                arguments=[\"--linalg-generalize-named-ops\"]\n",
    "            )\n",
    "        ),\n",
    "        (\n",
    "            mo.md(\n",
    "                \"\"\"We prepare the result tensors for bufferization:\"\"\"\n",
    "            ),\n",
    "            EmptyTensorToAllocTensorPass()\n",
    "        ),\n",
    "        (\n",
    "            mo.md(\n",
    "                \"\"\"We then use MLIR to bufferize our function:\"\"\"\n",
    "            ),\n",
    "            MLIROptPass(\n",
    "                arguments=[\n",
    "                    \"--one-shot-bufferize=bufferize-function-boundaries function-boundary-type-conversion=identity-layout-map\",\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "linalg_html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nWHF",
   "metadata": {},
   "source": [
    "From here we can use a number of backends to generate executable code, like LLVM, or RISC-V assembly directly.\n",
    "Please see other notebooks for details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iLit",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<span class=\"codehilite\"><div class=\"highlight\"><pre><span></span><span class=\"gt\">Traceback (most recent call last):</span>\n",
      "  File <span class=\"nb\">&quot;/Users/sasha/Developer/xdslproject/xdsl/.venv/lib/python3.12/site-packages/marimo/_runtime/executor.py&quot;</span>, line <span class=\"m\">141</span>, in <span class=\"n\">execute_cell</span>\n",
      "<span class=\"w\">    </span><span class=\"n\">exec</span><span class=\"p\">(</span><span class=\"n\">cell</span><span class=\"o\">.</span><span class=\"n\">body</span><span class=\"p\">,</span> <span class=\"n\">glbls</span><span class=\"p\">)</span>\n",
      "  File <span class=\"nb\">&quot;/var/folders/84/ql679qw90tdc6pkg78v59jl40000gn/T/marimo_84608/__marimo__cell_iLit_.py&quot;</span>, line <span class=\"m\">2</span>, in <span class=\"n\">&lt;module&gt;</span>\n",
      "<span class=\"w\">    </span><span class=\"kn\">from</span><span class=\"w\"> </span><span class=\"nn\">xdsl.frontend.onnx.ir_builder</span><span class=\"w\"> </span><span class=\"kn\">import</span> <span class=\"n\">build_module</span>\n",
      "  File <span class=\"nb\">&quot;/Users/sasha/Developer/xdslproject/xdsl/xdsl/frontend/onnx/ir_builder.py&quot;</span>, line <span class=\"m\">1</span>, in <span class=\"n\">&lt;module&gt;</span>\n",
      "<span class=\"w\">    </span><span class=\"kn\">from</span><span class=\"w\"> </span><span class=\"nn\">onnx</span><span class=\"w\"> </span><span class=\"kn\">import</span> <span class=\"n\">GraphProto</span><span class=\"p\">,</span> <span class=\"n\">NodeProto</span><span class=\"p\">,</span> <span class=\"n\">ValueInfoProto</span>\n",
      "<span class=\"gr\">ModuleNotFoundError</span>: <span class=\"n\">No module named &#39;onnx&#39;</span>\n",
      "</pre></div>\n",
      "</span>"
     ]
    }
   ],
   "source": [
    "from xdsl.context import MLContext\n",
    "from xdsl.frontend.onnx.ir_builder import build_module\n",
    "from xdsl.ir import Attribute, SSAValue\n",
    "from xdsl.passes import PipelinePass\n",
    "from xdsl.tools.command_line_tool import get_all_dialects\n",
    "from xdsl.transforms.convert_onnx_to_linalg import ConvertOnnxToLinalgPass\n",
    "from xdsl.transforms.empty_tensor_to_alloc_tensor import EmptyTensorToAllocTensorPass\n",
    "from xdsl.transforms.mlir_opt import MLIROptPass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZHCJ",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "outputs": [],
   "source": [
    "import marimo as mo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ROlb",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "outputs": [],
   "source": [
    "import xdsl.utils.marimo as xmo"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
